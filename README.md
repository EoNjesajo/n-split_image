# n-split_image
상기 방법은 위성 영상에서 Semantic Segmentation을 수행하는데 있어, 데이터를 무작위로 선별하여 새로우 데이터를 생성하는 방법으로, 원본 데이터셋에서 4^n개의 이미지를 선별해 각 이미지를 4^n등분하여 임의의 집합에 저장한 후, 이를 불러와 새로우 이미지를 생성함으로써 데이터으 양으 증대시킨다. 이를 통해 원본 이미지를 활용하여 추가 이미지를 생성할 수 있고, 이는 Semantic Segmentation에서 성능 향상으로 이어진다.

## 배경
Semantic Segmentation에서 있어, 데이터의 양은 성능을 좌지우지하고, 부족할 경우에는 충분히 학습하지 못하는 상황에 도달하게 된다. 이를 해결하기 위해 원본 데이터셋을 활용하여 새로운 데이터를 생성하는 방법에 대해 고안하게 된다.

## 해결수단
4n개의 원본 이미지를 선별한 후 각각 4^n등분하여 집합에 순서대로 저장해놓는 단계, 집합에 저장돼있는 4^n개의 이미지에서 원본 이미지 당 하나씩 지정한 4^n개의 이미지를 원본 이미지의 크기와 동일하게 이어붙이는 단계로 구성되며, n에 따라 4, 16, 64분할 또는 그 이상의 분할 이미지를 생성할 수 있다.

<img width="425" alt="image" src="https://user-images.githubusercontent.com/90492809/169636994-e87d1c9d-b7e5-42c2-8f5e-9234c228e254.png">

이를 통해 생성할 수 있는 이미지를 아래와 같다(도로와 건물을 검출하기 위한 위성영상)
<img width="623" alt="스크린샷 2022-05-21 오후 2 24 32" src="https://user-images.githubusercontent.com/90492809/169637055-a6c62c6a-6396-4e5f-ab00-741313523fe5.png">

## 실험 환경과 결과 
### 데이터셋
  |Class|Train|Valid|
  |------|------|-----|
  |3개(배경포함)|212개|212개|<br><br>
  
### 공통된 설정
  |index|value|
  |------|------|
  |Model Architecture|UNet++|
  |Optimizer|Adam|
  |Loss|DiceLoss|
  |Evaluation Metric|mIoU|<br><br>
 
 ### 차별된 설정(4n분할 이미지 추가)
  |16분할 이미지|64분할 이미지|
  |------|------|
  |1012개|1012개|br><br>
  
 ### 실험 결과
  |분류|이미지 갯수|mIoU|
  |------|------|------|
  |기본|212개|69.5%|
  |16분할|1224개|75.6%|
  |64분할|1224개|77.7%|br><br>
  

## 효과
기존의 데이터를 활용하여 새로운 데이터를 생성할 수 있으며, 분할 횟수에 따라 기존 데이터의 수보다 더 많은 데이터를 확보할 수 있다. 
최근 CPS와 같이 라벨을 가지지 않은 이미지를 추가 데이터로 사용하여 학습시키는 Semi supervised Semantic Segmentation이 연구되고 있지만, 이는 충분한 성능을 확보하지 못했을 때 저조한 개선 혹은 성능 하락을 야기한다. 그러기 때문에, 새롭게 생성된 4n분할 이미지는 데이터가 부족하다는 본질적인 문제를 해결할 수 있다. 
하지만 분할 횟수가 증가할수록 데이터가 복잡한 형태를 가지게 되고, 초당 분할 이미지 수인 FPS가 감소하게 된다. 그래서 중요시하는 성능 지표에 따라 분할 횟수를 설정해야한다. 또한, 건물과 도로를 검출하는 보 실험 환경과 달리 Sementic Segmentation은 더 다양한 객체에 대해 예측을 수행한다. 건물과 도로와 달리 분할을 수행했을 때 객체의 특징을 훼손할 수 있고, 이는 부정적인 영향을 야기할 수 있다.
